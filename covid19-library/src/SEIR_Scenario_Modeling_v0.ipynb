{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from configs.base_config import TrainingModuleConfig\n",
    "from configs.base_config import ModelEvaluatorConfig\n",
    "\n",
    "from modules.data_fetcher_module import DataFetcherModule\n",
    "from modules.forecasting_module import ForecastingModule\n",
    "from configs.base_config import ForecastingModuleConfig\n",
    "from modules.model_evaluator import ModelEvaluator\n",
    "from modules.training_module import TrainingModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_config.json') as f_train, \\\n",
    "    open('test_config.json') as f_test, \\\n",
    "    open('forecast_config.json') as f_forecast:\n",
    "    default_train_config = json.load(f_train)\n",
    "    default_test_config = json.load(f_test)\n",
    "    default_forecast_config = json.load(f_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_params(parameters, interval='Train1'):\n",
    "    \"\"\"\n",
    "        Flatten the params dictionary to enable logging\n",
    "    of the parameters.\n",
    "    \n",
    "    Assumptions:\n",
    "        There is a maximum of one level of nesting.\n",
    "        Ensured using an assert statement for now.\n",
    "        \n",
    "    Sample_input:\n",
    "        {\n",
    "            'LatentEbyCRatio': {\n",
    "                '4/7/20': 0.5648337712691847,\n",
    "                '4/17/20': 1.1427545912005197\n",
    "            },\n",
    "            'LatentIbyCRatio': {\n",
    "                '4/7/20': 0.9610881623714099,\n",
    "                '4/17/20': 0.6742970940209254\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    Output:\n",
    "        {\n",
    "            'Train1_LatentEbyCRatio_4/7/20': 0.5648337712691847,\n",
    "            'Train1_LatentEbyCRatio_4/17/20': 1.1427545912005197,\n",
    "            'Train1_LatentIbyCRatio_4/7/20': 0.9610881623714099,\n",
    "            'Train1_LatentIbyCRatio_4/17/20': 0.6742970940209254\n",
    "        }\n",
    "    \"\"\"\n",
    "    param_dict = dict() # The flattened dictionary to return\n",
    "    for param in parameters:\n",
    "        if isinstance(parameters[param], dict):\n",
    "            for key in parameters[param]:\n",
    "                assert (not isinstance(parameters[param][key], dict))\n",
    "                \n",
    "                param_dict[interval + '_' + param + '_'+ key] = parameters[param][key]\n",
    "        else:\n",
    "            param_dict[interval + '_' + param] = parameters[param]\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(region, region_type, \n",
    "               train1_start_date, train1_end_date, \n",
    "               train2_start_date, train2_end_date, run_day,\n",
    "               test_start_date, test_end_date, max_evals = 1000, \n",
    "               data_source = None, mlflow_log = True, name_prefix = None):\n",
    "    \"\"\"\n",
    "        #TODO: Need to add hooks to consume data from appropriate source\n",
    "\n",
    "        Run train and evalation for (basic) SEIR model.\n",
    "    \n",
    "    Arguments:\n",
    "        region, region_type : Region info corresponding to the run\n",
    "        train1_start_date, train1_end_date : Train1 durations\n",
    "        train2_start_date, train2_end_date : Train2 durations\n",
    "        test_start_date, test_end_date, run_day : Test durations\n",
    "        max_evals : number of search evaluations for SEIR (default: 1000)\n",
    "        data_source : Data source for picking the region data\n",
    "        mlflow_log : Experiment logged using MLFlow (default: True)\n",
    "        name_prefix : In case of non-MLFlow experiment, string prefix to\n",
    "                      enable easy indexing of experiments\n",
    "\n",
    "    Note:\n",
    "        date_format : %-m/%-d/%-y\n",
    "\n",
    "    Returns: \n",
    "        params : Run parameters to be logged\n",
    "        metrics : Metrics collected from the run \n",
    "    \n",
    "    Output files saved : (name_prefix added in the case of non-MLflow experiments)\n",
    "        Train1 : train1_output.json (name_prefix + '_train1_output.json')\n",
    "        Train2 : train2_output.json (name_prefix + '_train2_output.json')\n",
    "        Test   : test_output.json   (name_prefix + '_test_output.json')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Save metrics and params for logging\n",
    "    params = dict()\n",
    "    metrics = dict()\n",
    "\n",
    "    params['region'] = region\n",
    "    params['region_type'] = region_type\n",
    "    params['train1_start_date'] = train1_start_date\n",
    "    params['train1_end_date'] = train1_end_date\n",
    "    params['train2_start_date'] = train2_start_date\n",
    "    params['train2_end_date'] = train2_end_date\n",
    "    params['run_day'] = run_day\n",
    "    params['test_start_date'] = test_start_date\n",
    "    params['test_end_date'] = test_end_date\n",
    "    params['data_source'] = data_source\n",
    "    \n",
    "    # model parameters\n",
    "    model_params = dict()\n",
    "    model_params['region'] = region\n",
    "    model_params['region_type'] = region_type\n",
    "    model_params['model_type'] = \"SEIR\"\n",
    "    \n",
    "\n",
    "    train_config = deepcopy(default_train_config)\n",
    "    train_config['region_name'] = region\n",
    "    train_config['region_type'] = region_type\n",
    "    train_config['train_start_date'] = train1_start_date\n",
    "    train_config['train_end_date'] = train1_end_date\n",
    "    train_config['search_parameters']['max_evals'] = max_evals\n",
    "    \n",
    "    if mlflow_log:\n",
    "        train_config['output_filepath'] = 'train1_output.json'\n",
    "    else:\n",
    "        assert name_prefix is not None\n",
    "        train_config['output_filepath'] = name_prefix + '_train1_output.json'\n",
    "\n",
    "    train_module_config = TrainingModuleConfig.parse_obj(train_config)\n",
    "    trainResults = TrainingModule.from_config(train_module_config)\n",
    "    \n",
    "    metrics['Train1MAPE'] = trainResults['train_metric_results'][0]['value']\n",
    "    metrics['Train1RMLSE'] = trainResults['train_metric_results'][1]['value']\n",
    "    metrics.update(parse_params(trainResults['best_params'], 'Train1'))\n",
    "    metrics.update(parse_params(trainResults['latent_params'], 'Train1')) \n",
    "    \n",
    "    test_config = deepcopy(default_test_config)\n",
    "    test_config['region_name'] = region\n",
    "    test_config['region_type'] = region_type\n",
    "    test_config['test_start_date'] = test_start_date\n",
    "    test_config['test_end_date'] = test_end_date\n",
    "    test_config['run_day'] = run_day\n",
    "    test_config['model_parameters'].update(trainResults['best_params'])    \n",
    "    test_config['model_parameters'].update(trainResults['latent_params'])  \n",
    "        \n",
    "    if mlflow_log:\n",
    "        test_config['output_filepath'] = 'test_output.json'\n",
    "    else:\n",
    "        test_config['output_filepath'] = name_prefix + '_test_output.json'\n",
    "\n",
    "    test_module_config = ModelEvaluatorConfig.parse_obj(test_config) \n",
    "    evalResults = ModelEvaluator.from_config(test_module_config)\n",
    "    \n",
    "    metrics['TestMAPE'] = evalResults[0]['value']\n",
    "    metrics['TestRMLSE'] = evalResults[1]['value']\n",
    "    \n",
    "    \n",
    "    finalTrain_config = deepcopy(default_train_config)\n",
    "    finalTrain_config['region_name'] = region\n",
    "    finalTrain_config['region_type'] = region_type\n",
    "    finalTrain_config['train_start_date'] = train2_start_date\n",
    "    finalTrain_config['train_end_date'] = train2_end_date\n",
    "    finalTrain_config['search_parameters']['max_evals'] = max_evals\n",
    "    \n",
    "    if mlflow_log:\n",
    "        finalTrain_config['output_filepath'] = 'train2_output.json'\n",
    "    else:\n",
    "        finalTrain_config['output_filepath'] = name_prefix + '_train2_output.json'\n",
    "\n",
    "    finalTrain_module_config = TrainingModuleConfig.parse_obj(finalTrain_config)\n",
    "    finalResults = TrainingModule.from_config(finalTrain_module_config)\n",
    "    \n",
    "    metrics['Train2MAPE'] = finalResults['train_metric_results'][0]['value']\n",
    "    metrics['Train2RMLSE'] = finalResults['train_metric_results'][1]['value']\n",
    "    metrics.update(parse_params(finalResults['best_params'], 'Train2'))\n",
    "    metrics.update(parse_params(finalResults['latent_params'], 'Train2'))\n",
    "        \n",
    "    model_params['model_parameters'] = dict()\n",
    "    model_params['model_parameters'].update(finalResults['best_params'])\n",
    "    model_params['model_parameters'].update(finalResults['latent_params'])\n",
    "    model_params['model_parameters']['MAPE'] = finalResults['train_metric_results'][0]['value']\n",
    "    \n",
    "    return params, metrics, model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def override_parameters(model_params, param_override):\n",
    "    \"\"\"\n",
    "        Enable overriding of SEIR model parameters.\n",
    "        \n",
    "    Arguments:\n",
    "        model_params   : Original SEIR model params. Note that the \n",
    "                         expected format is the same as the one \n",
    "                         shared with the backend API.\n",
    "        param_override : Dictionary of parameters and new values \n",
    "                         for overriding.\n",
    "    \n",
    "    Returns:\n",
    "        model_params : Updated model_params. Note that we make a deepcopy of the\n",
    "                       model_param dictionary.\n",
    "\n",
    "    Example:\n",
    "    model_params =  {'region': 'mumbai',\n",
    "                     'region_type': 'district',\n",
    "                     'model_type': 'SEIR',\n",
    "                     'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
    "                      'IbyCRatio': 0.877531106686125,\n",
    "                      'infectious_period': 5.031419911631426,\n",
    "                      'r0': 0.5169788535587769,\n",
    "                      'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
    "                       '4/22/20': 0.1780890696175734},\n",
    "                      'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
    "                       '4/22/20': 0.2511722686138453},\n",
    "                      'MAPE': 8.768146390596282,\n",
    "                      'incubation_period': 5}}\n",
    "    param_override = {'r0': 1.1, 'incubation_period' : 3}\n",
    "    \n",
    "    Return:\n",
    "    model_params =  {'region': 'mumbai',\n",
    "                     'region_type': 'district',\n",
    "                     'model_type': 'SEIR',\n",
    "                     'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
    "                      'IbyCRatio': 0.877531106686125,\n",
    "                      'infectious_period': 5.031419911631426,\n",
    "                      'r0': 1.1,\n",
    "                      'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
    "                       '4/22/20': 0.1780890696175734},\n",
    "                      'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
    "                       '4/22/20': 0.2511722686138453},\n",
    "                      'MAPE': 8.768146390596282,\n",
    "                      'incubation_period': 3}}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure that the original dictionary remains unaltered\n",
    "    updated_params = deepcopy(model_params)\n",
    "    param_dict = updated_params['model_parameters']\n",
    "    \n",
    "    # Additional sanity check for keys in param_override\n",
    "    # Check if the param_override dict contains only\n",
    "    # valid keys from the model parameters\n",
    "    model_keys = set(param_dict.keys())\n",
    "    override_keys = set(param_override.keys())\n",
    "    \n",
    "    # Assert that the keys in override are a subset of the \n",
    "    # keys in the original model parameters\n",
    "    assert not (override_keys - model_keys)\n",
    "    \n",
    "    \n",
    "    # Override the parameters\n",
    "    param_dict.update(param_override)\n",
    "    \n",
    "    return updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params =  {'region': 'mumbai',\n",
    "                 'region_type': 'district',\n",
    "                 'model_type': 'SEIR',\n",
    "                 'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
    "                  'IbyCRatio': 0.877531106686125,\n",
    "                  'infectious_period': 5.031419911631426,\n",
    "                  'r0': 0.5169788535587769,\n",
    "                  'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
    "                   '4/22/20': 0.1780890696175734},\n",
    "                  'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
    "                   '4/22/20': 0.2511722686138453},\n",
    "                  'MAPE': 8.768146390596282,\n",
    "                  'incubation_period': 5}}\n",
    "param_override = {'r0': 1.1, 'incubation_period' : 3}\n",
    "updated_params = override_parameters(model_params, param_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'region': 'mumbai',\n",
       " 'region_type': 'district',\n",
       " 'model_type': 'SEIR',\n",
       " 'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
       "  'IbyCRatio': 0.877531106686125,\n",
       "  'infectious_period': 5.031419911631426,\n",
       "  'r0': 1.1,\n",
       "  'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
       "   '4/22/20': 0.1780890696175734},\n",
       "  'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
       "   '4/22/20': 0.2511722686138453},\n",
       "  'MAPE': 8.768146390596282,\n",
       "  'incubation_period': 3}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'region': 'mumbai',\n",
       " 'region_type': 'district',\n",
       " 'model_type': 'SEIR',\n",
       " 'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
       "  'IbyCRatio': 0.877531106686125,\n",
       "  'infectious_period': 5.031419911631426,\n",
       "  'r0': 0.5169788535587769,\n",
       "  'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
       "   '4/22/20': 0.1780890696175734},\n",
       "  'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
       "   '4/22/20': 0.2511722686138453},\n",
       "  'MAPE': 8.768146390596282,\n",
       "  'incubation_period': 5}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervention to model map\n",
    "\n",
    "### Model the impact of the following interventions\n",
    "* Testing rate\n",
    "* Fraction of population in containment\n",
    "* Fraction of population wearing masks\n",
    "\n",
    "### High level overview of mapping interventions to model parameters\n",
    "Each of the 3 interventions from above impact the virus dynamics which can be tied to model parameters.\n",
    "\n",
    "Current assumptions on the impact of each of the interventions\n",
    "r0 - goes down with increasing fraction of mask wearing population and containment\n",
    "incubation_period - goes down with increased testing\n",
    "infectious_period - goes down with more testing and containment (more isolation)\n",
    "\n",
    "Interventions are specifed as a dictionary\n",
    "```\n",
    "interventions = {‘testing_rate’: 0.5, ‘containment_fraction’: 0.4, ’mask_compliance’:0.9}\n",
    "```\n",
    "\n",
    "Interventions impact the parameters by linear scaling factors (Ignore the specific values)\n",
    "```\n",
    "scale_factor = {\n",
    "    'MASK_R0_DROP' : 0.1,\n",
    "    'CONTAINMENT_R0_DROP' : 0.2,\n",
    "    'TESTING_TINC_DROP' : 0.3,\n",
    "    'TESTING_TINF_DROP' : 0.4,\n",
    "    'CONTAINMENT_TINF_DROP' : 0.5\n",
    "}\n",
    "```\n",
    "\n",
    "The specific expression is specified as a dictionary to evaluate the change factor (WIP)\n",
    "```\n",
    "change_factor_map = {\n",
    "    'testing_rate' : [('incubation_period' , lambda x : 1 - x * scale_factor['TESTING_TINC_DROP']), \n",
    "                      ('infectious_period' , lambda x : 1 - x * scale_factor['TESTING_TINF_DROP'])],\n",
    "    'containment_fraction' : [('infectious_period' , lambda x : 1 - x * scale_factor['CONTAINMENT_TINF_DROP']),\n",
    "                              ('r0' , lambda x : 1 - x * scale_factor['CONTAINMENT_R0_DROP'])],\n",
    "    'mask_compliance' : [('r0' , lambda x : 1 - x * scale_factor['MASK_R0_DROP'])]\n",
    "}\n",
    "```\n",
    "\n",
    "Say the intervention we apply is \n",
    "```\n",
    "all_interventions = {'mask_compliance' : 0.9}\n",
    "```\n",
    "\n",
    "From the change factor map, we know that it impacts 'r0'.\n",
    "Further, let the original 'r0' was 0.5\n",
    "\n",
    "We compute the change_factor using the expression\n",
    "change_factor = 1 - 0.9 * 0.1 = 0.91\n",
    "The new 'r0' value will be = 0.91 * 0.5 = 0.455\n",
    "\n",
    "We use the intervention and change_factor_map to evaluate the change_factor\n",
    "```\n",
    "param_change = {}\n",
    "for intervention in all_interventions:\n",
    "    factors = change_factor_map[intervention]\n",
    "    level = all_interventions[intervention]\n",
    "    for (param, expr) in factors:\n",
    "        param_change[param] = expr(level)\n",
    "```\n",
    "\n",
    "We then compute the updated model parameters as follows\n",
    "```\n",
    "derived_model_params ={}\n",
    "for p in base_model_params:\n",
    "    p_val = base model_params[p]\n",
    "    p_val = p_val*param_change[p]\n",
    "derived_model_params[p] = p_val\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = {\n",
    "    'MASK_R0_DROP' : 0.5,\n",
    "    'CONTAINMENT_R0_DROP' : 0.5,\n",
    "    'TESTING_TINC_DROP' : 0.5,\n",
    "    'TESTING_TINF_DROP' : 0.5,\n",
    "    'CONTAINMENT_TINF_DROP' : 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change factor map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_factor_map = {\n",
    "    'testing_rate' : [('incubation_period' , lambda x : 1 - x * scale_factor['TESTING_TINC_DROP']), \n",
    "                      ('infectious_period' , lambda x : 1 - x * scale_factor['TESTING_TINF_DROP'])],\n",
    "    'containment_fraction' : [('infectious_period' , lambda x : 1 - x * scale_factor['CONTAINMENT_TINF_DROP']),\n",
    "                              ('r0' , lambda x : 1 - x * scale_factor['CONTAINMENT_R0_DROP'])],\n",
    "    'mask_compliance' : [('r0' , lambda x : 1 - x * scale_factor['MASK_R0_DROP'])]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute individual change_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to account for intervention impacting multiple parameters\n",
    "def change_factors(all_interventions):\n",
    "    param_change_factor = {}\n",
    "    for intervention in all_interventions:\n",
    "        factors = change_factor_map[intervention]\n",
    "        level = all_interventions[intervention]\n",
    "        for (param, expr) in factors:\n",
    "            param_change_factor[param] = expr(level)\n",
    "    return param_change_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute model parameters on applying an intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_intervention(model_paramters, all_interventions):\n",
    "    \"\"\"\n",
    "        Update the SEIR model paramters based on the interventions\n",
    "    applied.\n",
    "    \n",
    "    Arguments:\n",
    "        model_parameters  : Original SEIR model params. Note that the \n",
    "                            expected format is the same as the one \n",
    "                            shared with the backend API. \n",
    "        all_interventions : Dictionary of interventions and levels of interventions\n",
    "    \n",
    "    Returns:\n",
    "        updated_params    : Model paramters updated depending on the interventions\n",
    "    \"\"\"\n",
    "    # Ensure that the original dictionary remains unaltered\n",
    "    updated_params = deepcopy(model_params)\n",
    "    param_dict = updated_params['model_parameters']\n",
    "\n",
    "    param_change_factor = change_factors(all_interventions)\n",
    "    for param in param_dict:\n",
    "        p_val = param_dict[param]\n",
    "        \n",
    "        if param in param_change_factor:\n",
    "            p_val = p_val*param_change_factor[param]\n",
    "        \n",
    "        # Update the parameters\n",
    "        param_dict[param] = p_val\n",
    "    \n",
    "    return updated_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample intervention update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params =  {'region': 'mumbai',\n",
    "                 'region_type': 'district',\n",
    "                 'model_type': 'SEIR',\n",
    "                 'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
    "                  'IbyCRatio': 0.877531106686125,\n",
    "                  'infectious_period': 5.031419911631426,\n",
    "                  'r0': 0.5169788535587769,\n",
    "                  'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
    "                   '4/22/20': 0.1780890696175734},\n",
    "                  'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
    "                   '4/22/20': 0.2511722686138453},\n",
    "                  'MAPE': 8.768146390596282,\n",
    "                  'incubation_period': 5}}\n",
    "all_interventions = {'mask_compliance' : 0.9}\n",
    "updated_params = apply_intervention(model_params, all_interventions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'region': 'mumbai',\n",
       " 'region_type': 'district',\n",
       " 'model_type': 'SEIR',\n",
       " 'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
       "  'IbyCRatio': 0.877531106686125,\n",
       "  'infectious_period': 5.031419911631426,\n",
       "  'r0': 0.2843383694573273,\n",
       "  'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
       "   '4/22/20': 0.1780890696175734},\n",
       "  'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
       "   '4/22/20': 0.2511722686138453},\n",
       "  'MAPE': 8.768146390596282,\n",
       "  'incubation_period': 5}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'region': 'mumbai',\n",
       " 'region_type': 'district',\n",
       " 'model_type': 'SEIR',\n",
       " 'model_parameters': {'EbyCRatio': 0.5369542220931649,\n",
       "  'IbyCRatio': 0.877531106686125,\n",
       "  'infectious_period': 5.031419911631426,\n",
       "  'r0': 0.5169788535587769,\n",
       "  'LatentEbyCRatio': {'4/12/20': 0.5369542220931649,\n",
       "   '4/22/20': 0.1780890696175734},\n",
       "  'LatentIbyCRatio': {'4/12/20': 0.877531106686125,\n",
       "   '4/22/20': 0.2511722686138453},\n",
       "  'MAPE': 8.768146390596282,\n",
       "  'incubation_period': 5}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:covid] *",
   "language": "python",
   "name": "conda-env-covid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
